{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Although it is called regression, it is actually classification. Here we consider the case that the dependent variables are labeled either $+1$ or $-1$. Given an observatoin $x_n$, we estimate the probability of $y_n $ being $+1$ by\n",
    "$$ h(x_n)= \\frac{1}{1+e^{-W^tx_n}}$$\n",
    "Then our goal is find $W$\n",
    "$$ \\max _W h(x_1)h(x_2)(1-h(x_3))\\cdots $$\n",
    "where we use $h(x_n)$ if $y_n = 1$ and $(1-h(x_n))$ if $y_n = -1$.\n",
    "Intuitively, to maximize the target function, we want to make $h(x_n)$ very close to 1 if $y_n$ is 1, close to 0 is $y_n$  if $-1$.\n",
    "\n",
    "Since $1-h(x)=h(-x)$, the above optimization problem is equivalent to \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "& &\\max _W \\prod _n h(y_nx_n)\\\\\n",
    "& \\Leftrightarrow& \\min _W - \\frac{1}{N}\\sum _n \\ln h(y_nx_n)\\\\\n",
    "& \\Leftrightarrow& \\min _W \\frac{1}{N}\\sum \\ln (1+e^{-y_nW^tx_n})\n",
    "\\end{eqnarray*}\n",
    "\n",
    "So we can think $E := \\frac{1}{N}\\sum \\ln (1+e^{-y_nW^tx_n})$ as error. Intuitively, to make it small it's better to predict correctly. \n",
    "\n",
    "To use the gradient decent method, we compute\n",
    "\\begin{equation*}\n",
    " \\partial _{w_i}E = \\frac{1}{N}\\sum _n \\frac{e^{-y_nW^tx_n}}{1+e^{-y_nW^tx_n}}\\cdot -y_ix_{n,i}\n",
    "\\end{equation*}\n",
    "Then the iterative process is \n",
    "\\begin{equation*}\n",
    "W_{t+1} = W_t -\\eta \\frac{\\nabla E}{\\mid\\nabla E \\mid}\n",
    "\\end{equation*}\n",
    "\n",
    "A better choice of $\\eta$ is monotonic with $\\mid\\nabla E \\mid$, so the above equatoin becomes\n",
    "\\begin{equation*}\n",
    "W_{t+1} = W_t -\\eta \\nabla E\n",
    "\\end{equation*}\n",
    "\n",
    "Once we get an esimation of $w$, we can compute the score by plug in \n",
    "$w$ and $x_n$ into $h(\\cdot)$. If the score is greater than 0.5, then \n",
    "$\\hat{y} =$ 1 otherwise -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "%pylab inline\n",
    "\n",
    "\n",
    "def gradient(w, x, y):\n",
    "    # w:    features                 np.array\n",
    "    # x:    independent variables    pd.DataFrame\n",
    "    # y:\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    \n",
    "    s = np.dot(x, w.transpose()).reshape(n,1)*y\n",
    "    theta = np.exp(-s)/(1+np.exp(-s))\n",
    "    without_sum = theta*(-y*x)\n",
    "    gradient = (np.sum(without_sum, axis = 0))/n\n",
    "    return gradient\n",
    "\n",
    "def update(w, eta, gradient):\n",
    "    return w - eta*gradient\n",
    "\n",
    "def error(w, x, y):\n",
    "    n = x.shape[0]\n",
    "    score = 1 / 1+ np.exp(-np.dot(x, w.transpose()))\n",
    "    predict = (np.where(score>=0.5, 1.0, -1)).reshape((n,1))\n",
    "    \n",
    "    return sum(predict != y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"http://www.ats.ucla.edu/stat/data/binary.csv\")\n",
    "df.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"http://www.ats.ucla.edu/stat/data/binary.csv\")\n",
    "df.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "df[\"admit\"] = df[\"admit\"].replace(0, -1)\n",
    "x = df[[\"gre\", \"gpa\", \"prestige\"]]\n",
    "y = df[[\"admit\"]]\n",
    "\n",
    "\n",
    "\n",
    "#print df.describe()\n",
    "\n",
    "#df.hist()\n",
    "#pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit    127\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "w = np.array([0.11,0.1,0.1])\n",
    "for i in range(10000):\n",
    "    w = update(w, 0.1,gradient(w,x,y))\n",
    "\n",
    "#sum(predict!= y)\n",
    "print error(w, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.dot(x, w.transpose()).reshape(400,1)*np.array(y)\n",
    "t = np.exp(-s)/(np.ones((400,1))+ np.exp(-s))\n",
    "without_sum = t*(-y*x)\n",
    "sol = np.sum(without_sum, axis = 0)\n",
    "sol.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100,    2,    4])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([1,2,4])\n",
    "y = np.array([1,1,1])\n",
    "tt = np.where(z>=2, z, -100)\n",
    "tt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
